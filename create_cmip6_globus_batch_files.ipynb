{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7434e95d",
   "metadata": {},
   "source": [
    "# create_cmip6_globus_batch_files.ipynb\n",
    "Create Globus batch files and scripts for ESGF CMIP6 data of interest.\n",
    "\n",
    "B. Grandey, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe99d2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 19 09:54:11 +08 2022\r\n"
     ]
    }
   ],
   "source": [
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72b85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json.__version__ = 2.0.9\n",
      "pandas.__version__ = 1.3.5\n",
      "pyesgf.__version__ = 0.3.0\n",
      "re.__version__ = 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pyesgf\n",
    "from pyesgf.search import SearchConnection\n",
    "import re\n",
    "\n",
    "# Print versions of packages\n",
    "for module in [json, pd, pyesgf, re]:\n",
    "    try:\n",
    "        print('{}.__version__ = {}'.format(module.__name__, module.__version__))\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9584e30",
   "metadata": {},
   "source": [
    "## Base paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46c4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path in which to save batch files and scripts\n",
    "out_base = pathlib.Path('cmip6_globus_batch_files/').resolve()\n",
    "out_base.mkdir(exist_ok=True)  # create directory if it does not yet exist\n",
    "# Directory in which to save local cache for search connection\n",
    "cache_dir = pathlib.Path('cache/').resolve()\n",
    "cache_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df4a14",
   "metadata": {},
   "source": [
    "## Establish search connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b483a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyesgf.search.connection.SearchConnection at 0x7ff815c30730>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish search connection\n",
    "expire_after = datetime.timedelta(days=10)  # cache expiry\n",
    "conn = SearchConnection('https://esgf-node.llnl.gov/esg-search',\n",
    "                        distrib=True,\n",
    "                        cache='cache/pyesgf_cache',  # enable local cache\n",
    "                        expire_after=expire_after)\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd45da",
   "metadata": {},
   "source": [
    "## Identify suitable sources (models) and members (ripf variants)\n",
    "Do this by finding source-member pairs that fulfil the following requirements:\n",
    "1. Monthly data are available for at least one of 'zostoga', 'zos', and 'tas' variables.\n",
    "2. Data are available for at least one of 'ssp585', 'ssp370', 'ssp245', and 'ssp126' experiments.\n",
    "3. Data are available for both 'historical' and 'piControl' experiments.\n",
    "4. The member is an 'r1i1' variant (e.g. 'r1i1p1f1', 'r1i1p5f2')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc19b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "ACCESS-ESM1-5 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "AWI-CM-1-1-MR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "BCC-CSM2-MR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "BCC-ESM1 r1i1p1f1: ['historical', 'piControl', 'ssp370']\n",
      "CAMS-CSM1-0 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CAS-ESM2-0 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CESM2 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CESM2-WACCM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CIESM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp585']\n",
      "CMCC-CM2-SR5 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CMCC-ESM2 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CNRM-CM6-1 r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CNRM-CM6-1-HR r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CNRM-ESM2-1 r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CanESM5 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CanESM5 r1i1p2f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "CanESM5-CanOE r1i1p2f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "E3SM-1-1 r1i1p1f1: ['historical', 'piControl', 'ssp245', 'ssp585']\n",
      "EC-Earth3 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "EC-Earth3-AerChem r1i1p1f1: ['historical', 'piControl', 'ssp370']\n",
      "EC-Earth3-CC r1i1p1f1: ['historical', 'piControl', 'ssp245', 'ssp585']\n",
      "EC-Earth3-Veg r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "EC-Earth3-Veg-LR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "FGOALS-f3-L r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "FGOALS-g3 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "FIO-ESM-2-0 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp585']\n",
      "GFDL-CM4 r1i1p1f1: ['historical', 'piControl', 'ssp585']\n",
      "GFDL-ESM4 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "GISS-E2-1-G r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "GISS-E2-1-G r1i1p3f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "GISS-E2-1-G r1i1p5f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "GISS-E2-1-H r1i1p3f1: ['historical', 'piControl', 'ssp245', 'ssp370']\n",
      "IITM-ESM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "INM-CM4-8 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "INM-CM5-0 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "IPSL-CM5A2-INCA r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp370']\n",
      "IPSL-CM6A-LR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "KACE-1-0-G r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "KIOST-ESM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp585']\n",
      "MIROC-ES2L r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "MIROC6 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "MPI-ESM-1-2-HAM r1i1p1f1: ['historical', 'piControl', 'ssp370']\n",
      "MPI-ESM1-2-HR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "MPI-ESM1-2-LR r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "MRI-ESM2-0 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "NESM3 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp585']\n",
      "NorESM2-LM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "NorESM2-MM r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "TaiESM1 r1i1p1f1: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "UKESM1-0-LL r1i1p1f2: ['historical', 'piControl', 'ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
      "51 source-member pairs identified.\n",
      "CPU times: user 422 ms, sys: 82 ms, total: 504 ms\n",
      "Wall time: 558 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create dictionary to hold available experiments (list) for each source-member pair (tuple)\n",
    "source_member_experiment_dict = dict()\n",
    "# Perform initial search for datasets matching first two requirements above\n",
    "ctx1 = conn.new_context(project='CMIP6',\n",
    "                        variable=['zostoga', 'zos', 'tas'],\n",
    "                        frequency='mon',\n",
    "                        experiment_id=['ssp585', 'ssp370', 'ssp245', 'ssp126'])\n",
    "# Loop over available sources\n",
    "sources = sorted(ctx1.facet_counts['source_id'].keys())\n",
    "for source_id in sources:\n",
    "    # Constrain search to source, to identify available members\n",
    "    ctx2 = ctx1.constrain(source_id=source_id)\n",
    "    # Find r1i1 members (requirement #4)\n",
    "    members = sorted(ctx2.facet_counts['member_id'].keys())\n",
    "    members = [m for m in members if bool(re.match('r1i1', m))]\n",
    "    # Loop over members\n",
    "    for member_id in members:\n",
    "        # Search for available experiments for this source-member pair\n",
    "        ctx3 = conn.new_context(project='CMIP6',\n",
    "                                variable=['zostoga', 'zos', 'tas'],\n",
    "                                frequency='mon',\n",
    "                                source_id=source_id,\n",
    "                                member_id=member_id)\n",
    "        experiments = sorted(ctx3.facet_counts['experiment_id'].keys())\n",
    "        # Limit to experiments of interest\n",
    "        experiments = [e for e in experiments if e in ['piControl', 'historical',\n",
    "                                                       'ssp585', 'ssp370', 'ssp245', 'ssp126']]\n",
    "        # Are data available for both the historical and piControl experiments?\n",
    "        if ('historical' in experiments) and ('piControl' in experiments):\n",
    "            # Save to dictionary\n",
    "            source_member_experiment_dict[(source_id, member_id)] = experiments\n",
    "            # Print\n",
    "            print(f'{source_id} {member_id}: {experiments}')\n",
    "# Summarise number of source-member pairs identified\n",
    "print(f'{len(source_member_experiment_dict)} source-member pairs identified.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abce7db",
   "metadata": {},
   "source": [
    "## Function to find Globus URLs and write Globus batch files for a source-member pair\n",
    "\n",
    "If one wishes to only find only one Globus URL for each unique NetCDF file, then it is faster to search for dataset results then skip datasets with an instance_id that has already been processed.\n",
    "However, NetCDF files may be missed in practice: some Globus URLs may be inaccessible due to problems with endpoint accessibility, non-existent paths etc.\n",
    "Therefore, it makes sense to build in some redundancy by including every Globus URL.\n",
    "\n",
    "In light of these considerations, the function below performs a file search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2132d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_globus_batch_files(source_id='ACCESS-CM2',\n",
    "                             member_id='r1i1p1f1',\n",
    "                             variables=['zostoga',],\n",
    "                             frequency='mon',\n",
    "                             experiments=['piControl', 'historical', 'ssp585', 'ssp370', 'ssp245', 'ssp126'],\n",
    "                             conn=conn):\n",
    "    \"\"\"Find Globus URLs and write Globus batch files for a CMIP6 source-member pair.\n",
    "    \n",
    "    Keyword arguments:\n",
    "      source_id -- string: ESGF source_id / model (default 'ACCESS-CM2')\n",
    "      member_id -- string; ESGF member_id / ripf variant (default 'r1i1p1f1')\n",
    "      variables -- list: variables of interest (default ['zostoga',])\n",
    "      frequency -- string: time frequency of variable (default 'mon') \n",
    "      experiments -- list: experiment_id for experiments of interest\n",
    "          (default ['piControl', 'historical', 'ssp585', 'ssp370', 'ssp245', 'ssp126'])\n",
    "      conn -- pyesgf SearchConnection (default is a SearchConnection named 'conn')\n",
    "    \n",
    "    Returns:\n",
    "      batch_fn_ep_dict -- dict: names of the batch files written (keys) with corresponding endpoint (values)\n",
    "    \"\"\"\n",
    "    print(f'---- {source_id} {member_id} ----')\n",
    "    # Create DataFrame to hold Globus info etc for search results\n",
    "    globus_df = pd.DataFrame(columns=['variable', 'filename',\n",
    "                                      'globus_url',  # URL (suitably unique to also use as index)\n",
    "                                      'globus_ep', 'globus_path',  # Globus source endpoint and path\n",
    "                                      'dest_path'])  # target path on destination endpoint\n",
    "    # Loop over variables\n",
    "    for v in variables:\n",
    "        # File search context\n",
    "        ctx1 = conn.new_context(project='CMIP6',\n",
    "                                source_id=source_id,\n",
    "                                member_id=member_id,\n",
    "                                variable=v,\n",
    "                                frequency=frequency,\n",
    "                                experiment_id=experiments,\n",
    "                                latest=True,\n",
    "                                search_type='File')\n",
    "        # Perform search and loop over file results\n",
    "        file_results = ctx1.search()\n",
    "        print(f'{v}: {len(file_results)} file results to process.')\n",
    "        for f in file_results:\n",
    "            # Is result marked as retracted? If so, then skip.\n",
    "            if f.json['retracted']:\n",
    "                continue\n",
    "            # Does Globus URL exist?\n",
    "            globus_url = f.globus_url\n",
    "            if globus_url:\n",
    "                # Identify endpoint\n",
    "                globus_ep = globus_url.split('/')[0]\n",
    "                globus_ep = globus_ep.replace('globus:', '')\n",
    "                if len(globus_ep) != 36:\n",
    "                    print(f'globus_ep = \"{globus_ep}\" looks suspect. Skipping.')\n",
    "                else:\n",
    "                    # Path on endpoint\n",
    "                    globus_path = globus_url.split(f'{globus_ep}/')[1]\n",
    "                    # Target path on local endpoint (relative to $GCP_EP_CMIP6 environment variable)\n",
    "                    instance_id = f.json['dataset_id'].split('|')[0]  # dataset's instance_id\n",
    "                    dest_path = f'{v}/{source_id}_{member_id}/{instance_id}/{f.filename}'\n",
    "                    # Update DataFrame\n",
    "                    globus_df.at[globus_url] = {'variable': v, 'filename': f.filename,\n",
    "                                                'globus_url': globus_url,\n",
    "                                                'globus_ep': globus_ep, 'globus_path': globus_path,\n",
    "                                                'dest_path': dest_path}\n",
    "        # Print number of URLs found\n",
    "        print(f'{v}: {globus_df[\"variable\"].value_counts()[v]} Globus URLs saved.')\n",
    "    # Dict to hold batch filenames (keys) and source endpoints (values)\n",
    "    batch_fn_ep_dict = dict()\n",
    "    # Loop over source endpoints\n",
    "    for globus_ep in globus_df['globus_ep'].value_counts().index:\n",
    "        # Select subset of data for this endpoint\n",
    "        ep_df = globus_df[globus_df['globus_ep']==globus_ep]\n",
    "        # Get name of endpoint using Globus CLI\n",
    "        ep_json = ! globus endpoint show -F json {globus_ep}\n",
    "        ep_json = json.loads(''.join(ep_json))\n",
    "        ep_name = ep_json['display_name']\n",
    "        print(f'{ep_name}: {len(ep_df)} files in batch.')\n",
    "        # Label for transfer\n",
    "        if len(variables) == 1:\n",
    "            var_str = variables[0]\n",
    "        elif len(variables) == 2:\n",
    "            var_str = '-'.join(variables)\n",
    "        else:\n",
    "            var_str = f'{len(variables)}vars-inc-{variables[0]}'\n",
    "        if len(experiments) == 1:\n",
    "            exp_str = experiments[0]\n",
    "        else:\n",
    "            exp_str = f'{len(experiments)}exps'\n",
    "        batch_label = f'{source_id}_{member_id}_{frequency}_{var_str}_{exp_str}_{globus_ep}'\n",
    "        # Filename of batch file to write\n",
    "        batch_fn = f'{batch_label}.txt'\n",
    "        # Directory in which to write batch file\n",
    "        batch_dir = out_base.joinpath(globus_ep)\n",
    "        batch_dir.mkdir(exist_ok=True)\n",
    "        # Write batch file\n",
    "        with open(batch_dir.joinpath(batch_fn), 'w') as writer:\n",
    "            writer.write(f'# Written by write_globus_batch_files() in create_cmip6_globus_batch_files.ipynb '\n",
    "                         + f'on {datetime.date.today()}\\n')\n",
    "            writer.write(f'# Globus endpoint is {globus_ep} (Name: {ep_name}).\\n')\n",
    "            writer.write(f'# {len(ep_df)} files in batch.\\n')\n",
    "            writer.write(f'# To activate source endpoint use Globus CLI:\\n')\n",
    "            writer.write(f'# globus endpoint activate --web {globus_ep}\\n')\n",
    "            writer.write(f'# To submit transfer use Globus CLI:\\n')\n",
    "            writer.write(f'# globus transfer {globus_ep} $GCP_EP_CMIP6 --batch {batch_fn} '\n",
    "                         + f'--preserve-mtime --fail-on-quota-errors --skip-source-errors --sync-level checksum '\n",
    "                         + f'--label \"{batch_label}\"\\n')\n",
    "            writer.write(f'# Replace $GCP_EP_CMIP6 with intended destination endpoint, including base path.\\n')\n",
    "            writer.write('\\n')\n",
    "            for i in ep_df.index:  # loop over rows of DataFrame\n",
    "                globus_path = ep_df.loc[i]['globus_path']\n",
    "                dest_path = ep_df.loc[i]['dest_path']\n",
    "                writer.write(f'{globus_path} {dest_path}\\n')\n",
    "            print(f'Written {batch_fn} ({len(ep_df)} files).')\n",
    "            batch_fn_ep_dict[batch_fn] = globus_ep\n",
    "    return batch_fn_ep_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040fe12",
   "metadata": {},
   "source": [
    "## TODO: Write batch files for source-member pairs identified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f0dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to hold all batch_fn_ep_dict results returned by write_globus_batch_files()\n",
    "main_batch_fn_ep_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5719b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8774f6",
   "metadata": {},
   "source": [
    "## Write batch files for specific combinations of source-member pair, variables, frequency, and experiments\n",
    "Specific custom combinations can be added in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee103a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- ACCESS-CM2 r1i1p1f1 ----\n",
      "thetao: 65 file results to process.\n",
      "thetao: 53 Globus URLs saved.\n",
      "NCI ESGF: 29 files in batch.\n",
      "Written ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_2058c7d6-a79f-11e6-9ad6-22000a1e3b52.txt (29 files).\n",
      "LLNL ESGF: 12 files in batch.\n",
      "Written ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_415a6320-e49c-11e5-9798-22000b9da45e.txt (12 files).\n",
      "CEDA ESGF DN1: 12 files in batch.\n",
      "Written ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_ee3aa1a0-7e4c-11e6-afc4-22000b92c261.txt (12 files).\n"
     ]
    }
   ],
   "source": [
    "# List containing tuples of custom combinations (source_id, member_id, variables, frequency, experiments)\n",
    "comb_list = [('ACCESS-CM2', 'r1i1p1f1', ['thetao',], 'mon', ['ssp585',],),  # test 3D variable\n",
    "             ]\n",
    "# Produce batch file for each custom combination\n",
    "for comb in comb_list:\n",
    "    source_id, member_id, variables, frequency, experiments = comb\n",
    "    temp_dict = write_globus_batch_files(source_id=source_id,\n",
    "                                         member_id=member_id,\n",
    "                                         variables=variables,\n",
    "                                         frequency=frequency,\n",
    "                                         experiments=experiments)\n",
    "    main_batch_fn_ep_dict.update(temp_dict)  # update dictionary with new filenames and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25763b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_2058c7d6-a79f-11e6-9ad6-22000a1e3b52.txt': '2058c7d6-a79f-11e6-9ad6-22000a1e3b52', 'ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_415a6320-e49c-11e5-9798-22000b9da45e.txt': '415a6320-e49c-11e5-9798-22000b9da45e', 'ACCESS-CM2_r1i1p1f1_mon_thetao_ssp585_ee3aa1a0-7e4c-11e6-afc4-22000b92c261.txt': 'ee3aa1a0-7e4c-11e6-afc4-22000b92c261'}\n"
     ]
    }
   ],
   "source": [
    "print(main_batch_fn_ep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "120d795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 19 09:54:21 +08 2022\r\n"
     ]
    }
   ],
   "source": [
    "! date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
